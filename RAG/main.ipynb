{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T08:55:16.499994Z",
     "start_time": "2024-07-11T08:55:14.412405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import streamlit as st\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:06:23.456906Z",
     "start_time": "2024-07-11T09:06:23.452339Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:06:40.614442Z",
     "start_time": "2024-07-11T09:06:39.586714Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = ChatOpenAI(api_key=openai_api_key, model=\"gpt-3.5-turbo\", temperature=0.2)\n",
    "parser = StrOutputParser()"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T09:07:52.204620Z",
     "start_time": "2024-07-11T09:07:28.444075Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_loader = PyPDFLoader('Hitachi Manual.pdf')\n",
    "pages = file_loader.load_and_split()\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "split_pages = splitter.split_documents(pages)\n",
    "vector_storage = FAISS.from_documents(split_pages, OpenAIEmbeddings())\n",
    "retriever = vector_storage.as_retriever()\n",
    "question_template = \"\"\"\n",
    "You're a smart chatbot that answers user generated prompts only based on the context given to you.\n",
    "You don't make any assumptions.\n",
    "context:{context}\n",
    "question:{question}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(template=question_template)"
   ],
   "outputs": [],
   "execution_count": 14
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
